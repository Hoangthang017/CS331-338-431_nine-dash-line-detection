{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Extraction using Alexnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM0XddoDqiw1n5mJmacTlM+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hoangthang017/CS331-338-431_nine-dash-line-detection/blob/continues_learn_about_Faster-RCNN/FeatureExtractionUsingAlexnet/Feature_Extraction_using_Alexnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axfDE5iepesd",
        "outputId": "42e32c28-bd25-40b2-934d-b837d93b7f2e"
      },
      "source": [
        "# mount gg drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab4CQxnbKoGW"
      },
      "source": [
        "# import library\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "from imutils import paths\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpC9p-cFzJ-s"
      },
      "source": [
        "# define Alexnet Architecture\n",
        "class Alexnet:\n",
        "  def __init__(self, cs = 1000,  bp = \"FC3\"):\n",
        "    self.classifer = cs\n",
        "    self.breakPoint = bp\n",
        "    self.model = None\n",
        "\n",
        "  # setting model\n",
        "  def define_model(self):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(227,227,3)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096,activation='relu'))\n",
        "\n",
        "    # feature extraction in FC1\n",
        "    if (self.breakPoint == \"FC1\"):\n",
        "      self.model = model\n",
        "      return\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096,activation='relu'))\n",
        "\n",
        "    # feature extraction in FC2\n",
        "    if (self.breakPoint == \"FC2\"):\n",
        "      self.model = model\n",
        "      return\n",
        "    \n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(self.classifer,activation='softmax'))\n",
        "    self.model = model\n",
        "\n",
        "  # predict \n",
        "  def predict(self, data):\n",
        "    return self.model.predict(data)\n",
        "\n",
        "  # get summary of model\n",
        "  def summary(self):\n",
        "    print(self.model.summary())\n",
        "\n",
        "  # get model\n",
        "  def get_model(self):\n",
        "    return self.model\n",
        "\n",
        "  # get/set break point\n",
        "  def get_breakPoint(self):\n",
        "    return self.breakPoint\n",
        "  def set_breakPoint(self, bp):\n",
        "    self.breakPoint = bp\n",
        "\n",
        "  # get/set class\n",
        "  def get_class(self):\n",
        "    return self.classifer\n",
        "  def set_class(self, c):\n",
        "    self.classifer = c"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwIqyUJbv1kN"
      },
      "source": [
        "# get feature from model\n",
        "def getFeature(imagePath, model):\n",
        "  # preprocess image\n",
        "  image = load_img(imagePath,target_size=(227,227))\n",
        "  img_array = img_to_array(image)\n",
        "  img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "  # get feature \n",
        "  feature = model.predict(img_array)\n",
        "  feature = feature.reshape(-1)\n",
        "\n",
        "  return feature"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N9dnUZb4wO_"
      },
      "source": [
        "# feature extraction\n",
        "def featureExtraction(imageDir, model):\n",
        "  imagePaths = list(paths.list_images(imageDir))\n",
        "\n",
        "  features = []\n",
        "  labels = []\n",
        "\n",
        "  for imagePath in imagePaths:\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    features.append(getFeature(imagePath,model))\n",
        "\n",
        "    if (label == \"Lines\"):\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      labels.append(0)\n",
        "  \n",
        "  # create dataFrame\n",
        "  # dataset = pd.DataFrame(\n",
        "  # {\n",
        "  #   \"Featrues\": features,\n",
        "  #   \"labels\" : labels   \n",
        "  # })\n",
        "  return np.array(features),np.array(labels)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6ohj0ZV0H9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c0c357-84bc-4191-f790-cfc4c0e7eef6"
      },
      "source": [
        "# main function\n",
        "if __name__ ==  \"__main__\":\n",
        "  pathDir = '/content/drive/MyDrive/Data Nine-Dash-Lines'\n",
        "\n",
        "  # setting model\n",
        "  model = Alexnet(cs=2,bp=\"FC1\")\n",
        "  model.define_model()\n",
        "  model.summary()\n",
        "\n",
        "  # feature extraction\n",
        "  # FC1\n",
        "  features_1 , labels_1 = featureExtraction(pathDir, model)\n",
        "  np.savetxt(\"/content/drive/MyDrive/Data Nine-Dash-Lines/DataFrame/FC1_features.txt\",features_1)\n",
        "  np.savetxt(\"/content/drive/MyDrive/Data Nine-Dash-Lines/DataFrame/FC1_labels.txt\",labels_1)\n",
        "\n",
        "  # FC2\n",
        "  model.set_breakPoint(bp=\"FC2\")\n",
        "  model.define_model()\n",
        "  model.summary()\n",
        "  features_2, labels_2 = featureExtraction(pathDir, model)\n",
        "  np.savetxt(\"/content/drive/MyDrive/Data Nine-Dash-Lines/DataFrame/FC2_features.txt\",features_2)\n",
        "  np.savetxt(\"/content/drive/MyDrive/Data Nine-Dash-Lines/DataFrame/FC2_labels.txt\",labels_2)\n",
        "\n",
        "  # # show \n",
        "  # print(dt_feature)\n",
        "  # print(dataset.shape)\n",
        "\n",
        "  # print(dataset2)\n",
        "  # print(dataset.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 55, 55, 96)        34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 55, 55, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 27, 27, 256)       614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 27, 27, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 13, 13, 384)       885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 13, 13, 384)       1536      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 13, 13, 384)       1536      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 256)       884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 13, 13, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              37752832  \n",
            "=================================================================\n",
            "Total params: 41,505,536\n",
            "Trainable params: 41,502,784\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 55, 55, 96)        34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 55, 55, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 27, 27, 256)       614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 27, 27, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 13, 13, 384)       885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 13, 13, 384)       1536      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 13, 13, 384)       1536      \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 13, 13, 256)       884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 13, 13, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              37752832  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "=================================================================\n",
            "Total params: 58,286,848\n",
            "Trainable params: 58,284,096\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4cK7XfvbgtS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}